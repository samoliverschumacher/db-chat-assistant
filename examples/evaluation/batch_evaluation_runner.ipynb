{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run multiple evaluation modes for a configuration & set of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approach: sql_engine_w_reranking\n",
      "database:\n",
      "  metadata:\n",
      "    document_id_like: '%-2'\n",
      "    metadata_path: sqlite:///data/chinook.db\n",
      "    table_name: table_descriptions\n",
      "  path: sqlite:///data/chinook.db\n",
      "index:\n",
      "  class: ollama\n",
      "  name: llama2reranker\n",
      "  reranking:\n",
      "    config_object: ReRankerLLMConfig\n",
      "    reranker_kwargs:\n",
      "      top_n: 3\n",
      "  retriever_kwargs:\n",
      "    similarity_top_k: 4\n",
      "llm:\n",
      "  class: ollama\n",
      "  name: llama2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "from dbchat import ROOT_DIR\n",
    "\n",
    "config_path = ROOT_DIR.parent / \"tests/data/inputs/cfg_3.yml\"\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "print(yaml.dump(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 datasets, one with target/expected agent responses and one without\n",
    "\n",
    "\n",
    "Files should be in the following format:\n",
    "```csv\n",
    "id|user_query|tables|note|response\n",
    "1|How much money in Berlin?|invoices||Berlin made $74.2\n",
    "```\n",
    "\n",
    "Split the evaluation dataset into two files: queries with expected responses, and those without.\n",
    "\n",
    "```bash\n",
    "awk -F '|' '{ if ($5 == \"\") print > \"examples/evaluation/queries_no_response.csv\"; else print > \"examples/evaluation/queries_with_response.csv\" }' examples/evaluation/queries.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging Query: SELECT TABLE_NAME, DESCRIPTION FROM table_descriptions WHERE TABLE_NAME IN ('albums','artists','customers','employees','genres','invoice_items','invoices','media_types','playlist_track','playlists','artists'0,'artists'1) AND DOCUMENT_ID LIKE '%-2'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/ssch7/repos/db-chat-assistant/examples/evaluation/batch_evaluation_runner.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ssch7/repos/db-chat-assistant/examples/evaluation/batch_evaluation_runner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m test_data_path_with_responses\u001b[39m.\u001b[39mexists():\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ssch7/repos/db-chat-assistant/examples/evaluation/batch_evaluation_runner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m eval_funcs:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ssch7/repos/db-chat-assistant/examples/evaluation/batch_evaluation_runner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         r \u001b[39m=\u001b[39m f(test_data_path_with_responses, config_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ssch7/repos/db-chat-assistant/examples/evaluation/batch_evaluation_runner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m         pipeline_results\u001b[39m.\u001b[39mextend(r)\n",
      "File \u001b[0;32m/mnt/c/Users/ssch7/repos/db-chat-assistant/src/dbchat/evaluation/evaluate.py:260\u001b[0m, in \u001b[0;36mevaluate_synthetic_judge_with_query\u001b[0;34m(test_data_path, config_path)\u001b[0m\n\u001b[1;32m    257\u001b[0m queries \u001b[39m=\u001b[39m [ row[ \u001b[39m'\u001b[39m\u001b[39muser_query\u001b[39m\u001b[39m'\u001b[39m ] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m flattened_data ]\n\u001b[1;32m    258\u001b[0m expected_responses \u001b[39m=\u001b[39m [ row[ \u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m ] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m flattened_data ]\n\u001b[0;32m--> 260\u001b[0m batch_responses \u001b[39m=\u001b[39m run_batch_queries( queries, cfg, retrieve_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, use_cached_values \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m )\n\u001b[1;32m    262\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m    263\u001b[0m \u001b[39mfor\u001b[39;00m ( query, response ), expected_response \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m( batch_responses\u001b[39m.\u001b[39mitems(), expected_responses ):\n",
      "File \u001b[0;32m/mnt/c/Users/ssch7/repos/db-chat-assistant/src/dbchat/evaluation/evaluate.py:41\u001b[0m, in \u001b[0;36mrun_batch_queries\u001b[0;34m(queries, config, retrieve_only, use_cached_values)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m config[ \u001b[39m'\u001b[39m\u001b[39mapproach\u001b[39m\u001b[39m'\u001b[39m ] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msql_engine_w_reranking\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     tables \u001b[39m=\u001b[39m retriever\u001b[39m.\u001b[39mretrieve( query )\n\u001b[1;32m     42\u001b[0m     table_names \u001b[39m=\u001b[39m [ table\u001b[39m.\u001b[39mtable_name \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables ]\n\u001b[1;32m     43\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/c/Users/ssch7/repos/db-chat-assistant/src/dbchat/models/reranking.py:161\u001b[0m, in \u001b[0;36msql_query_engine_with_reranking.<locals>.retrieve_and_rerank\u001b[0;34m(query_str)\u001b[0m\n\u001b[1;32m    158\u001b[0m nodes_with_scores \u001b[39m=\u001b[39m original_retrieve_fn(query_str)\n\u001b[1;32m    160\u001b[0m query_bundle \u001b[39m=\u001b[39m QueryBundle(query_str)\n\u001b[0;32m--> 161\u001b[0m reranked_nodes \u001b[39m=\u001b[39m postprocessor\u001b[39m.\u001b[39mpostprocess_nodes(\n\u001b[1;32m    162\u001b[0m     nodes_with_scores, query_bundle)\n\u001b[1;32m    164\u001b[0m convert_to_schema \u001b[39m=\u001b[39m [\n\u001b[1;32m    165\u001b[0m     retriever\u001b[39m.\u001b[39m_object_node_mapping\u001b[39m.\u001b[39mfrom_node(node\u001b[39m.\u001b[39mnode)\n\u001b[1;32m    166\u001b[0m     \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m reranked_nodes\n\u001b[1;32m    167\u001b[0m ]\n\u001b[1;32m    168\u001b[0m \u001b[39mreturn\u001b[39;00m convert_to_schema\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/llama_index/postprocessor/types.py:48\u001b[0m, in \u001b[0;36mBaseNodePostprocessor.postprocess_nodes\u001b[0;34m(self, nodes, query_bundle, query_str)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_postprocess_nodes(nodes, query_bundle)\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/llama_index/postprocessor/llm_rerank.py:87\u001b[0m, in \u001b[0;36mLLMRerank._postprocess_nodes\u001b[0;34m(self, nodes, query_bundle)\u001b[0m\n\u001b[1;32m     85\u001b[0m fmt_batch_str \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_node_batch_fn(nodes_batch)\n\u001b[1;32m     86\u001b[0m \u001b[39m# call each batch independently\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m raw_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice_context\u001b[39m.\u001b[39mllm_predictor\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m     88\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoice_select_prompt,\n\u001b[1;32m     89\u001b[0m     context_str\u001b[39m=\u001b[39mfmt_batch_str,\n\u001b[1;32m     90\u001b[0m     query_str\u001b[39m=\u001b[39mquery_str,\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     93\u001b[0m raw_choices, relevances \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_choice_select_answer_fn(\n\u001b[1;32m     94\u001b[0m     raw_response, \u001b[39mlen\u001b[39m(nodes_batch)\n\u001b[1;32m     95\u001b[0m )\n\u001b[1;32m     96\u001b[0m choice_idxs \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(choice) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m raw_choices]\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/llama_index/llm_predictor/base.py:224\u001b[0m, in \u001b[0;36mLLMPredictor.predict\u001b[0;34m(self, prompt, output_cls, **prompt_args)\u001b[0m\n\u001b[1;32m    222\u001b[0m     formatted_prompt \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mformat(llm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_llm, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprompt_args)\n\u001b[1;32m    223\u001b[0m     formatted_prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_prompt(formatted_prompt)\n\u001b[0;32m--> 224\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_llm\u001b[39m.\u001b[39mcomplete(formatted_prompt)\n\u001b[1;32m    225\u001b[0m     output \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtext\n\u001b[1;32m    227\u001b[0m logger\u001b[39m.\u001b[39mdebug(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/llama_index/llms/base.py:313\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mwith\u001b[39;00m wrapper_logic(_self) \u001b[39mas\u001b[39;00m callback_manager:\n\u001b[1;32m    304\u001b[0m     event_id \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_event_start(\n\u001b[1;32m    305\u001b[0m         CBEventType\u001b[39m.\u001b[39mLLM,\n\u001b[1;32m    306\u001b[0m         payload\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m         },\n\u001b[1;32m    311\u001b[0m     )\n\u001b[0;32m--> 313\u001b[0m     f_return_val \u001b[39m=\u001b[39m f(_self, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f_return_val, Generator):\n\u001b[1;32m    315\u001b[0m         \u001b[39m# intercept the generator and add a callback to the end\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_gen\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m CompletionResponseGen:\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/llama_index/llms/ollama.py:130\u001b[0m, in \u001b[0;36mOllama.complete\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@llm_completion_callback\u001b[39m()\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomplete\u001b[39m(\u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m CompletionResponse:\n\u001b[1;32m    129\u001b[0m     response_gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_complete(prompt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 130\u001b[0m     response_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(response_gen)\n\u001b[1;32m    131\u001b[0m     final_response \u001b[39m=\u001b[39m response_list[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    132\u001b[0m     final_response\u001b[39m.\u001b[39mdelta \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/llama_index/llms/base.py:318\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen\u001b[0;34m()\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_gen\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m CompletionResponseGen:\n\u001b[1;32m    317\u001b[0m     last_response \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m f_return_val:\n\u001b[1;32m    319\u001b[0m         \u001b[39myield\u001b[39;00m cast(CompletionResponse, x)\n\u001b[1;32m    320\u001b[0m         last_response \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/llama_index/llms/ollama.py:162\u001b[0m, in \u001b[0;36mOllama.stream_complete.<locals>.gen\u001b[0;34m(response_iter)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen\u001b[39m(response_iter: Iterator[Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m CompletionResponseGen:\n\u001b[1;32m    161\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mfor\u001b[39;00m stream_response \u001b[39min\u001b[39;00m response_iter:\n\u001b[1;32m    163\u001b[0m         delta \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(stream_response)\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m         text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m delta\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/requests/models.py:865\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \n\u001b[1;32m    860\u001b[0m \u001b[39m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    863\u001b[0m pending \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_content(\n\u001b[1;32m    866\u001b[0m     chunk_size\u001b[39m=\u001b[39mchunk_size, decode_unicode\u001b[39m=\u001b[39mdecode_unicode\n\u001b[1;32m    867\u001b[0m ):\n\u001b[1;32m    869\u001b[0m     \u001b[39mif\u001b[39;00m pending \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    870\u001b[0m         chunk \u001b[39m=\u001b[39m pending \u001b[39m+\u001b[39m chunk\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/requests/utils.py:571\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[0;34m(iterator, r)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    570\u001b[0m decoder \u001b[39m=\u001b[39m codecs\u001b[39m.\u001b[39mgetincrementaldecoder(r\u001b[39m.\u001b[39mencoding)(errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 571\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m    572\u001b[0m     rv \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39mdecode(chunk)\n\u001b[1;32m    573\u001b[0m     \u001b[39mif\u001b[39;00m rv:\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/urllib3/response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 624\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[1;32m    625\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/urllib3/response.py:828\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 828\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_chunk_length()\n\u001b[1;32m    829\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    830\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/site-packages/urllib3/response.py:758\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline()\n\u001b[1;32m    759\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    760\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/db-chat/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from dbchat.evaluation.evaluate import evaluate_synthetic_judge, evaluate_synthetic_judge_with_query, evaluate_table_name_retrieval\n",
    "\n",
    "pipeline_results: List[dict] = []\n",
    "\n",
    "# For test data with only user query & expected tables;\n",
    "test_data_path_no_responses = ROOT_DIR.parent.parent / \"examples/evaluation/queries_no_response.csv\"\n",
    "if test_data_path_no_responses.exists():\n",
    "    eval_funcs = [evaluate_table_name_retrieval]\n",
    "    for f in eval_funcs:\n",
    "        r = f(test_data_path_no_responses, config_path)\n",
    "        pipeline_results.extend(r)\n",
    "\n",
    "# For test data with user query, and a target desired response;\n",
    "test_data_path_with_responses = ROOT_DIR.parent.parent / \"examples/evaluation/queries_with_response.csv\"\n",
    "eval_funcs = [evaluate_synthetic_judge_with_query,\n",
    "              evaluate_synthetic_judge,\n",
    "              evaluate_table_name_retrieval]\n",
    "if test_data_path_with_responses.exists():\n",
    "    for f in eval_funcs:\n",
    "        r = f(test_data_path_with_responses, config_path)\n",
    "        pipeline_results.extend(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using multiprocessing (untested)\n",
    " - Need to check the amount of CPU / IO processes in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "pipeline_results = []\n",
    "\n",
    "# For test data with only user query & expected tables;\n",
    "test_data_path_no_responses = \"examples/evaluation/queries_no_response.csv\"\n",
    "eval_funcs_no_responses = [evaluate_table_name_retrieval]\n",
    "\n",
    "# For test data with user query, and a target desired response;\n",
    "test_data_path_with_responses = \"examples/evaluation/queries_with_response.csv\"\n",
    "eval_funcs_with_responses = [evaluate_synthetic_judge_with_query,\n",
    "                             evaluate_synthetic_judge,\n",
    "                             evaluate_table_name_retrieval]\n",
    "\n",
    "# Create a multiprocessing pool\n",
    "pool = multiprocessing.Pool()\n",
    "\n",
    "# Run the first loop functions in parallel\n",
    "results_no_responses = pool.starmap(lambda f: f(test_data_path_no_responses, config_path), [(f,) for f in eval_funcs_no_responses])\n",
    "\n",
    "# Run the second loop functions in parallel\n",
    "results_with_responses = pool.starmap(lambda f: f(test_data_path_with_responses, config_path), [(f,) for f in eval_funcs_with_responses])\n",
    "\n",
    "# Extend the pipeline_results with the results from both loops\n",
    "for r in results_no_responses:\n",
    "    pipeline_results.extend(r)\n",
    "for r in results_with_responses:\n",
    "    pipeline_results.extend(r)\n",
    "\n",
    "# Close the multiprocessing pool\n",
    "pool.close()\n",
    "pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db-chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
